{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Decision Tree for Classification\n",
    "\n",
    "In this notebook, we have two tasks: exploratory data analysis (EDA), building a decision tree classifier. We use the same data set ([Iris](https://archive.ics.uci.edu/ml/datasets/iris)) for both tasks. Iris dataset contains 150 examples with 4 features (attributes). All features are real valued. There are 3 categories of iris species in the dataset reflected in the class label information: *Iris Setosa*, *Iris Versicolour*, *Iris Virginica*\n",
    "\n",
    "We will see the details of the data set in EDA part. We will use the Orange Python API for building a decision tree. A popular Python machine learning library Scikit-learn doesn't have proper decision tree implementation. See [here](https://github.com/scikit-learn/scikit-learn/issues/5442)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd Party Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import Orange\n",
    "import pandas as pd\n",
    "from graphviz import Digraph\n",
    "from Orange.preprocess import Impute\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for Tidying Data, Dimensionality Reduction, Tree Visualization, Performance Evaluation\n",
    "\n",
    "PCA and tSNE are commonly used dimensionality reduction techniques. Here, we provide functions to calculate their projections and utility functions to visualize these projections and decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_dataset(table):\n",
    "    \"\"\"Decomposes dataset into attributes and classes\"\"\"\n",
    "    return table.X, table.Y, table.domain.class_var.values\n",
    "\n",
    "\n",
    "def table2dataframe(table):\n",
    "    \"\"\"Converts Orange.Table to pandas.DataFrame\"\"\"\n",
    "    def map_values(vals, real):\n",
    "        return [real[i] for i in vals]\n",
    "\n",
    "    attributes = [attr.name for attr in table.domain.attributes]\n",
    "    target = table.domain.class_var.name\n",
    "\n",
    "    X, y, _ = decompose_dataset(table)\n",
    "\n",
    "    return table, pd.DataFrame(data=np.c_[X, y], columns=attributes + [target])\n",
    "\n",
    "\n",
    "def pca(dataset):\n",
    "    \"\"\"Performs PCA on dataset and returns the first two principal components\"\"\"\n",
    "    X, y, target_names = decompose_dataset(dataset)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    X_r = pca.fit_transform(X)\n",
    "\n",
    "    # Percentage of variance explained for each components\n",
    "    explained_var = sum(pca.explained_variance_ratio_)\n",
    "\n",
    "    return X_r, y, target_names, explained_var\n",
    "\n",
    "\n",
    "def tsne(dataset, itr=1000):\n",
    "    \"\"\"Performs tSNE and returns transformed dataset projection in 2D and label information\"\"\"\n",
    "    X, y, target_names = decompose_dataset(dataset)\n",
    "\n",
    "    tsne = TSNE(n_components=2, n_iter=itr)\n",
    "\n",
    "    X_r = tsne.fit_transform(X)\n",
    "\n",
    "    return X_r, y, target_names\n",
    "\n",
    "\n",
    "def plot_dim_reduce(X_r, y, target_names, ax=None, palette=\"tab10\", **kwargs):\n",
    "    \"\"\"Plots lower dimension projections\"\"\"\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    uniq_target = set(y)\n",
    "    colors = plt.get_cmap(palette)(np.arange(len(uniq_target), dtype=int))\n",
    "    lw = 2\n",
    "\n",
    "    for color, i, target_name in zip(colors, uniq_target, target_names):\n",
    "        ax.scatter(\n",
    "            X_r[y == i, 0],\n",
    "            X_r[y == i, 1],\n",
    "            color=color,\n",
    "            alpha=0.8,\n",
    "            lw=lw,\n",
    "            label=target_name,\n",
    "        )\n",
    "\n",
    "    ax.legend(loc=\"best\", shadow=True, scatterpoints=1)\n",
    "    ax.set_xlabel(kwargs[\"xtitle\"])\n",
    "    ax.set_ylabel(kwargs[\"ytitle\"])\n",
    "    ax.set_title(kwargs[\"title\"])\n",
    "\n",
    "\n",
    "def plot_pca_tsne(dataset, name):\n",
    "    \"\"\"Plots PCA and tSNE projections side by side\"\"\"\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "    X_r_pca, y, target_names, explained_var = pca(dataset)\n",
    "    title1 = \"{} -- Total Variation: %{:.3f}\".format(name, explained_var)\n",
    "    plot_dim_reduce(\n",
    "        X_r_pca, y, target_names, axes[0], xtitle=\"PC 1\", ytitle=\"PC 2\", title=title1\n",
    "    )\n",
    "\n",
    "    X_r_tsne, _, _ = tsne(dataset)\n",
    "    title2 = \"{} -- TSNE Visualization\".format(name)\n",
    "    plot_dim_reduce(\n",
    "        X_r_tsne, y, target_names, axes[1], xtitle=\"Dim 1\", ytitle=\"Dim 2\", title=title2\n",
    "    )\n",
    "\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "\n",
    "def class_dist(num_obs, labels, justified=\"\\l\"):\n",
    "    \"\"\"Calculates class distribution\"\"\"\n",
    "    dist = np.array(num_obs) / sum(num_obs)\n",
    "    dist_labels = dict(zip(labels, dist))\n",
    "\n",
    "    return justified.join([\"{} = {:.3f}\".format(k, v) for k, v in dist_labels.items()])\n",
    "\n",
    "\n",
    "def visualize_tree(tree, labels):\n",
    "    \"\"\"Plots resulting decision tree\"\"\"\n",
    "    def visualize_tree_aux(root, labels, dot=None):\n",
    "        if not dot:\n",
    "            dot = Digraph()\n",
    "            dot.attr(\"node\", shape=\"record\")\n",
    "            desc = class_dist(root.value, labels)\n",
    "            dot.node(name=str(root), label=\"{{{}|{}}}\".format(desc, root.attr.name))\n",
    "\n",
    "        for child in root.children:\n",
    "            if child:\n",
    "                attr = child.attr\n",
    "                desc = class_dist(child.value, labels)\n",
    "                if attr:\n",
    "                    dot.node(name=str(child), label=\"{{{}|{}}}\".format(desc, attr.name))\n",
    "                    dot.edge(str(root), str(child), label=child.description)\n",
    "                else:\n",
    "                    dot.node(name=str(child), label=\"{{{}|{}}}\".format(desc, \"\"))\n",
    "                    dot.edge(str(root), str(child), label=child.description)\n",
    "\n",
    "                visualize_tree_aux(child, labels, dot)\n",
    "\n",
    "        return dot\n",
    "\n",
    "    return visualize_tree_aux(tree.root, labels)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_performance(test, pred):\n",
    "    \"\"\"Calculates classification accuracy\"\"\"\n",
    "    result = Orange.evaluation.Results()\n",
    "    result.actual = test.Y\n",
    "    result.predicted = [pred]\n",
    "\n",
    "    ca = Orange.evaluation.CA()\n",
    "\n",
    "    return ca(result)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "Pandas-profiling library provides a very detailed `ProfileReport`. It is widget based, to get a better understanding of the data, navigate its tabs. Distribution of each attribute, interactions and correlations between attributes, missing values and duplicate rows are summarized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, df = table2dataframe(Orange.data.Table(\"iris\"))\n",
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\", explorative=True)\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction Plots\n",
    "\n",
    "PCA and tSNE are commonly used dimensionality reduction methods; see [this tutorial](https://medium.com/@violante.andre/an-introduction-to-t-sne-with-python-example-47e6ae7dc58f) for more information. Here, we show the resulting 2D projections of these methods on the Iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_tsne(dataset, \"iris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Decision Tree Model, Training and Testing Data Split\n",
    "\n",
    "We split the data set into training (80%) and testing (20%) using stratified sampling which ensures that the proportion of classes in the data set is reflected in splits. To prevent overfitting, pre-pruning schemes can be applied. In the `TreeLearner` class pre-pruning is controlled by `max_depth`, `min_samples_leaf`, `min_samples_split`, `sufficient_majority`. See [documentation](https://orange-data-mining-library.readthedocs.io/en/latest/reference/classification.html#Orange.classification.TreeLearner)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training, testing = Orange.evaluation.testing.sample(\n",
    "    dataset, n=0.8, stratified=True, replace=False\n",
    ")\n",
    "assert len(training) + len(testing) == len(dataset)\n",
    "\n",
    "learner = Orange.classification.TreeLearner(\n",
    "    max_depth=None, min_samples_leaf=1, min_samples_split=2, sufficient_majority=0.95\n",
    ")\n",
    "dt = learner(training)\n",
    "\n",
    "visualize_tree(dt, list(training.domain.class_var.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model\n",
    "\n",
    "We will report classification accuracy on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt(testing)\n",
    "\n",
    "acc = evaluate_performance(testing, y_pred)\n",
    "print(\"Classification Accuracy = {:.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "1. Change parameters of `TreeLearner` for pre-pruning. Report model accuracies and discuss your findings.\n",
    "2. Repeat all the steps for [heart_disease](http://archive.ics.uci.edu/ml/datasets/heart+Disease) data set `Orange.data.Table(\"heart_disease\")`.\n",
    "    - There are missing values in the data set. You need to impute the missing values for dimensionality reduction. Imputation module is already imported in required libraries cell. See [here](https://orange-data-mining-library.readthedocs.io/en/latest/reference/preprocess.html#impute)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n",
    "\n",
    "Please contact Haluk Dogan (<a href=\"mailto:hdogan@vivaldi.net\">hdogan@vivaldi.net</a>) for further questions or inquries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
